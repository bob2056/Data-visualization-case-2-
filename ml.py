# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PmFEaZ8GUd9xKM1dAmo4DdDybJRocUHV
"""




import os
import joblib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# sklearn imports
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report, roc_curve
)

# PDF/report imports
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image
from reportlab.lib.styles import getSampleStyleSheet

# Ensure plots display in Colab
# %matplotlib inline

# -----------------------
# 0. Configuration
# -----------------------
CLEANED_CSV = "/content/Chicago_Crimes_2012_2017_cleaned_.csv"
OUTPUT_DIR = "/mnt/data/ml_arrest_output"
os.makedirs(OUTPUT_DIR, exist_ok=True)
MODELS_DIR = os.path.join(OUTPUT_DIR, "models")
os.makedirs(MODELS_DIR, exist_ok=True)
PLOTS_DIR = os.path.join(OUTPUT_DIR, "plots")
os.makedirs(PLOTS_DIR, exist_ok=True)

# -----------------------
# 1. Load dataset
# -----------------------
print("Loading cleaned CSV:", CLEANED_CSV)
df = pd.read_csv(CLEANED_CSV, low_memory=False, parse_dates=['IncidentDate'], infer_datetime_format=True)

print("Initial shape:", df.shape)
display(df.head(3))

# -----------------------
# 2. Feature engineering & final cleaning
# -----------------------
# Create temporal features if not present
if 'IncidentDate' in df.columns:
    df['Hour'] = df['IncidentDate'].dt.hour.fillna(0).astype(int)
    df['Month'] = df['IncidentDate'].dt.month.fillna(0).astype(int)
    df['Weekday'] = df['IncidentDate'].dt.day_name().fillna('Unknown')
    df['Year'] = df['IncidentDate'].dt.year.fillna(0).astype(int)
else:
    # safe defaults if IncidentDate missing
    df['Hour'] = df.get('Hour', 0).fillna(0).astype(int)
    df['Month'] = df.get('Month', 0).fillna(0).astype(int)
    df['Weekday'] = df.get('Weekday', 'Unknown')
    df['Year'] = df.get('Year', 0).fillna(0).astype(int)

# Ensure target exists and is integer
if 'Arrest' not in df.columns:
    raise ValueError("Target column 'Arrest' not found in CSV.")
df['Arrest'] = df['Arrest'].fillna(0).astype(int)

# Columns detection for lat/lon
lat_col = next((c for c in df.columns if c.lower().startswith('lat')), None)
lon_col = next((c for c in df.columns if c.lower().startswith('lon')), None)

# Sanity-clean primary categorical fields
df['Primary Type'] = df.get('Primary Type', 'UNKNOWN').fillna('UNKNOWN').astype(str)
df['Location Description'] = df.get('Location Description', 'UNKNOWN').fillna('UNKNOWN').astype(str)
df['Domestic'] = df.get('Domestic', 0).fillna(0).astype(int)

# Reduce cardinality for categories (to keep one-hot manageable)
TOP_PRIMARY = 20
TOP_LOC = 20
top_primary = df['Primary Type'].value_counts().nlargest(TOP_PRIMARY).index.tolist()
df['Primary Type'] = df['Primary Type'].apply(lambda x: x if x in top_primary else 'OTHER')

top_loc = df['Location Description'].value_counts().nlargest(TOP_LOC).index.tolist()
df['Location Description'] = df['Location Description'].apply(lambda x: x if x in top_loc else 'OTHER_LOC')

# Ensure lat/lon numeric and fill median if missing
if lat_col and lon_col:
    df[lat_col] = pd.to_numeric(df[lat_col], errors='coerce')
    df[lon_col] = pd.to_numeric(df[lon_col], errors='coerce')
    df[lat_col] = df[lat_col].fillna(df[lat_col].median())
    df[lon_col] = df[lon_col].fillna(df[lon_col].median())

# Select feature set
features = ['Primary Type','Location Description','Domestic','Hour','Month','Weekday']
if lat_col and lon_col:
    features += [lat_col, lon_col]

print("Using features:", features)

# Drop rows with missing target (none expected)
df = df.dropna(subset=['Arrest'])

# -----------------------
# 3. Prepare X, y and split
# -----------------------
X = df[features].copy()
y = df['Arrest'].copy()

# Use stratified split to preserve balance in train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, stratify=y, random_state=42
)
print("Train/test sizes:", X_train.shape, X_test.shape)

# -----------------------
# 4. Build preprocessing pipeline
# -----------------------
categorical_cols = ['Primary Type','Location Description','Weekday']
numeric_cols = ['Hour','Month','Domestic']
if lat_col and lon_col:
    numeric_cols += [lat_col, lon_col]

preprocessor = ColumnTransformer(transformers=[
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
    ('num', StandardScaler(), numeric_cols)
], remainder='drop')

# -----------------------
# 5. Define models
# -----------------------
models = {
    'LogisticRegression': LogisticRegression(max_iter=1000),
    'RandomForest': RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42),
    'GradientBoosting': GradientBoostingClassifier(n_estimators=200, random_state=42),
    'AdaBoost': AdaBoostClassifier(n_estimators=200, random_state=42)
}

# -----------------------
# 6. Train, evaluate, save
# -----------------------
results = {}
roc_data = {}  # store fpr, tpr for ROC plots

for name, estimator in models.items():
    print(f"\nTraining {name} ...")
    pipe = Pipeline([('pre', preprocessor), ('clf', estimator)])
    pipe.fit(X_train, y_train)

    # Predict & probabilities
    y_pred = pipe.predict(X_test)
    try:
        y_prob = pipe.predict_proba(X_test)[:,1]
    except Exception:
        # some estimators may not have predict_proba
        y_prob = None

    # Metrics
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc = roc_auc_score(y_test, y_prob) if y_prob is not None else None

    results[name] = {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'roc_auc': roc}

    # Confusion matrix and classification report
    cm = confusion_matrix(y_test, y_pred)
    print(f"{name} classification report:\n", classification_report(y_test, y_pred, zero_division=0))
    print(f"{name} Confusion Matrix:\n", cm)

    # Save model
    model_path = os.path.join(MODELS_DIR, f"{name}.joblib")
    joblib.dump(pipe, model_path)
    print("Saved model to:", model_path)

    # Save ROC data for plotting
    if y_prob is not None:
        fpr, tpr, _ = roc_curve(y_test, y_prob)
        roc_data[name] = (fpr, tpr)

    # Save a simple plot for confusion matrix
    plt.figure(figsize=(4,3))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f"{name} Confusion Matrix")
    plt.colorbar()
    plt.xlabel('Predicted label')
    plt.ylabel('True label')
    for (i, j), z in np.ndenumerate(cm):
        plt.text(j, i, str(z), ha='center', va='center', color='white' if z > cm.max()/2 else 'black')
    cm_plot_path = os.path.join(PLOTS_DIR, f"{name}_confusion.png")
    plt.tight_layout()
    plt.savefig(cm_plot_path, dpi=150)
    plt.close()

# Print summary metrics table
metrics_df = pd.DataFrame(results).T
metrics_df = metrics_df[['accuracy','precision','recall','f1','roc_auc']]
print("\nSummary metrics:\n", metrics_df)

metrics_csv = os.path.join(OUTPUT_DIR, "model_metrics_summary.csv")
metrics_df.to_csv(metrics_csv)
print("Saved metrics to:", metrics_csv)

# -----------------------
# 7. Plot ROC curves for models that have probabilities
# -----------------------
plt.figure(figsize=(8,6))
for name, v in roc_data.items():
    fpr, tpr = v
    plt.plot(fpr, tpr, label=f"{name} (AUC={results[name]['roc_auc']:.3f})")
plt.plot([0,1],[0,1],"k--", linewidth=1)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves")
plt.legend(loc="lower right")
roc_plot_path = os.path.join(PLOTS_DIR, "roc_curves.png")
plt.tight_layout()
plt.savefig(roc_plot_path, dpi=150)
plt.show()
plt.close()
print("Saved ROC figure to:", roc_plot_path)

# -----------------------
# 8. Feature importance (for tree models)
# -----------------------
# Extract feature names after one-hot encoding
ohe = preprocessor.named_transformers_['cat']
cat_feature_names = []
if hasattr(ohe, 'get_feature_names_out'):
    cat_feature_names = list(ohe.get_feature_names_out(categorical_cols))
else:
    # fallback
    cat_feature_names = []
num_feature_names = numeric_cols
feature_names = cat_feature_names + num_feature_names

# Plot feature importances for RandomForest and GradientBoosting
for name in ['RandomForest','GradientBoosting']:
    if name in models:
        # load model pipeline
        pipe = joblib.load(os.path.join(MODELS_DIR, f"{name}.joblib"))
        # get the trained estimator in pipeline
        estimator = pipe.named_steps['clf']
        try:
            importances = estimator.feature_importances_
            # If length mismatch, skip (rare)
            if len(importances) == len(feature_names):
                imp_idx = np.argsort(importances)[::-1][:20]
                top_feats = [feature_names[i] for i in imp_idx]
                top_vals = importances[imp_idx]
                plt.figure(figsize=(8,6))
                plt.barh(range(len(top_vals))[::-1], top_vals, tick_label=top_feats)
                plt.title(f"{name} Top Feature Importances")
                plt.tight_layout()
                path = os.path.join(PLOTS_DIR, f"{name}_feature_importance.png")
                plt.savefig(path, dpi=150)
                plt.close()
                print(f"Saved feature importance for {name} to:", path)
            else:
                print(f"Feature importance length mismatch for {name}; skipping plot.")
        except Exception as e:
            print(f"Could not extract feature importances for {name}: {e}")

# -----------------------
# 9. Build a simple PDF report (metrics + key plots)
# -----------------------
pdf_path = os.path.join(OUTPUT_DIR, "ML_Arrest_Prediction_Report.pdf")
doc = SimpleDocTemplate(pdf_path, pagesize=letter)
styles = getSampleStyleSheet()

elements = []
elements.append(Paragraph("ML Report: Predicting Arrests (Sample)", styles['Title']))
elements.append(Spacer(1,12))
elements.append(Paragraph(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles['Normal']))
elements.append(Spacer(1,12))

elements.append(Paragraph("Model performance (summary):", styles['Heading2']))
# convert metrics_df to text paragraphs
for idx, row in metrics_df.iterrows():
    row_text = f"<b>{idx}</b>: Accuracy={row['accuracy']:.4f}, Precision={row['precision']:.4f}, Recall={row['recall']:.4f}, F1={row['f1']:.4f}, ROC_AUC={row['roc_auc']:.4f}" if not pd.isna(row['roc_auc']) else f"<b>{idx}</b>: Accuracy={row['accuracy']:.4f}, Precision={row['precision']:.4f}, Recall={row['recall']:.4f}, F1={row['f1']:.4f}, ROC_AUC=N/A"
    elements.append(Paragraph(row_text, styles['BodyText']))
    elements.append(Spacer(1,6))

# Add ROC image if exists
if os.path.exists(roc_plot_path):
    elements.append(Spacer(1,12))
    elements.append(Paragraph("ROC Curves:", styles['Heading2']))
    elements.append(Image(roc_plot_path, width=400, height=300))

# Add confusion matrices images
elements.append(Spacer(1,12))
elements.append(Paragraph("Confusion matrices (per model):", styles['Heading2']))
for name in models.keys():
    img_path = os.path.join(PLOTS_DIR, f"{name}_confusion.png")
    if os.path.exists(img_path):
        elements.append(Paragraph(name, styles['Heading3']))
        elements.append(Image(img_path, width=300, height=220))
        elements.append(Spacer(1,6))

doc.build(elements)
print("PDF report saved to:", pdf_path)

# Final print of results
print("\nFinal metrics table:")
print(metrics_df)
print("\nAll outputs (models, plots, report) saved under:", OUTPUT_DIR)
